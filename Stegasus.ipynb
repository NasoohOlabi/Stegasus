{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gM4tXm1xJ_JE"
      },
      "source": [
        "# Stegasus"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ODi5968TKDdR"
      },
      "source": [
        "## Commons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHLBkWQt3Hss",
        "outputId": "d35ce912-1fe0-4189-aeea-5264d06bb84c"
      },
      "outputs": [],
      "source": [
        "%pip install icecream\n",
        "from icecream import ic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AiAjOvuJ-0i"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XUOmnFcsF4yM"
      },
      "outputs": [],
      "source": [
        "#@title random_bit_stream\n",
        "import random\n",
        "\n",
        "def random_bit_stream(length=None):\n",
        "    \"\"\"Return a random string of zeros and ones of the given length (default: random integer between 0 and 100).\"\"\"\n",
        "    if length is None:\n",
        "        length = random.randint(0, 100)\n",
        "    return ''.join(str(random.randint(0, 1)) for _ in range(length))\n",
        "def int_to_binary_string(n: int, length: int):\n",
        "    binary_str = bin(n)[2:]  # convert to binary string, remove '0b' prefix\n",
        "    padded_str = binary_str.rjust(length, '0')  # pad with zeros to length\n",
        "    return padded_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMGfFY5CjLHB"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.insert(0, parent_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy9bCvx4G9KS"
      },
      "source": [
        "## Frustratingly Simple BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mohTMYaRHF0U"
      },
      "outputs": [],
      "source": [
        "#@title new masking approach\n",
        "import spacy\n",
        "\n",
        "def extract_pos(text):\n",
        "    \"\"\"Extract the start and end positions of verbs, nouns, and adjectives in the given text.\"\"\"\n",
        "    # Load the spaCy English model\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    \n",
        "    # Parse the text with spaCy\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    # Create a dictionary to store the start and end positions of each POS tag\n",
        "    pos_dict = {\n",
        "        'VERB': [],\n",
        "        'NOUN': [],\n",
        "        'ADJ': []\n",
        "    }\n",
        "    \n",
        "    # Loop through each token in the parsed text\n",
        "    for token in doc:\n",
        "        if token.pos_ in pos_dict:\n",
        "            # If the token's POS tag is a verb, noun, or adjective, add its start and end positions to the dictionary\n",
        "            pos_dict[token.pos_].append((token.idx, token.idx + len(token)))\n",
        "    \n",
        "    return pos_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdGvxtVQW_Pt",
        "outputId": "b6102fc5-2076-4ad4-900d-2a385179708e"
      },
      "outputs": [],
      "source": [
        "# @title Setup Installs Imports\n",
        "%pip install transformers\n",
        "%pip install icecream\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from typing import List, Tuple, Union\n",
        "from io import StringIO\n",
        "from icecream import ic \n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from transformers.tokenization_utils import PreTrainedTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN9JGVMwVv6k",
        "outputId": "bf089d2c-7842-4b41-9ea6-f21486eaedf1"
      },
      "outputs": [],
      "source": [
        "#@title Class Definition\n",
        "\n",
        "@dataclass\n",
        "class MaskedStegoResult:\n",
        "  encoded_text: str\n",
        "  encoded_bytes: str\n",
        "  remaining_bytes: str\n",
        "\n",
        "class MaskedStego:\n",
        "    debugging = False\n",
        "    def __init__(self, model_name_or_path: str = 'bert-base-cased') -> None:\n",
        "        self._tokenizer: PreTrainedTokenizer = BertTokenizer.from_pretrained(model_name_or_path)\n",
        "        self._model = BertForMaskedLM.from_pretrained(model_name_or_path)\n",
        "        self._STOPWORDS: List[str] = stopwords.words('english')\n",
        "\n",
        "    def __call__(self, cover_text: str, message: str, mask_interval: int = 3, score_threshold: float = 0.01) -> MaskedStegoResult:\n",
        "        assert set(message) <= set('01')\n",
        "        message_io = StringIO(message)\n",
        "        if self.debugging:\n",
        "          ic(message_io)\n",
        "        processed = self._preprocess_text(cover_text, mask_interval)\n",
        "        if self.debugging:\n",
        "          ic(processed)\n",
        "        input_ids = processed['input_ids']\n",
        "        # ic(input_ids)\n",
        "        masked_ids = processed['masked_ids']\n",
        "        # ic(masked_ids)\n",
        "        sorted_score, indices = processed['sorted_output']\n",
        "        # ic(sorted_score, indices)\n",
        "        for i_token, token in enumerate(masked_ids):\n",
        "            if self.debugging:\n",
        "              ic(i_token, token)\n",
        "            if self.debugging:\n",
        "              ic(self._tokenizer.mask_token_id)\n",
        "            if token != self._tokenizer.mask_token_id:\n",
        "                continue\n",
        "            ids = indices[i_token]\n",
        "            if self.debugging:\n",
        "              ic(ids)\n",
        "            scores = sorted_score[i_token]\n",
        "            if self.debugging:\n",
        "              ic(scores)\n",
        "            candidates = self._pick_candidates_threshold(ids, scores, score_threshold)\n",
        "            # ic(candidates)\n",
        "            if self.debugging:\n",
        "              ic(self._tokenizer.convert_ids_to_tokens(candidates))\n",
        "            if self.debugging:\n",
        "              ic(len(candidates) < 2)\n",
        "            if len(candidates) < 2:\n",
        "                continue\n",
        "            replace_token_id = self._block_encode_single(candidates, message_io).item()\n",
        "            if self.debugging:\n",
        "              ic(replace_token_id)\n",
        "            if self.debugging:\n",
        "              ic('replace', replace_token_id, self._tokenizer.convert_ids_to_tokens([replace_token_id]))\n",
        "            input_ids[i_token] = replace_token_id\n",
        "        encoded_message: str = message_io.getvalue()[:message_io.tell()]\n",
        "        if self.debugging:\n",
        "          ic(encoded_message)\n",
        "        message_io.close()\n",
        "        stego_text = self._tokenizer.decode(input_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "        if self.debugging:\n",
        "          ic(stego_text)\n",
        "        return MaskedStegoResult(encoded_text=stego_text,encoded_bytes=encoded_message,remaining_bytes=message[len(encoded_message):])\n",
        "\n",
        "    def decode(self, stego_text: str, mask_interval: int = 3, score_threshold: float = 0.005) -> str:\n",
        "        decoded_message: List[str] = []\n",
        "        processed = self._preprocess_text(stego_text, mask_interval)\n",
        "        input_ids = processed['input_ids']\n",
        "        masked_ids = processed['masked_ids']\n",
        "        sorted_score, indices = processed['sorted_output']\n",
        "        for i_token, token in enumerate(masked_ids):\n",
        "            if token != self._tokenizer.mask_token_id:\n",
        "                continue\n",
        "            ids = indices[i_token]\n",
        "            scores = sorted_score[i_token]\n",
        "            candidates = self._pick_candidates_threshold(ids, scores, score_threshold)\n",
        "            if len(candidates) < 2:\n",
        "                continue\n",
        "            chosen_id: int = input_ids[i_token].item()\n",
        "            decoded_message.append(self._block_decode_single(candidates, chosen_id))\n",
        "\n",
        "        return ''.join(decoded_message)\n",
        "\n",
        "    def _preprocess_text(self, sentence: str, mask_interval: int) -> dict:\n",
        "        encoded_ids = self._tokenizer([sentence], return_tensors='pt').input_ids[0]\n",
        "        masked_ids = self._mask(encoded_ids.clone(), mask_interval)\n",
        "        sorted_score, indices = self._predict(masked_ids)\n",
        "        return { 'input_ids': encoded_ids, 'masked_ids': masked_ids, 'sorted_output': (sorted_score, indices) }\n",
        "\n",
        "    def _mask(self, input_ids: Union[Tensor, List[List[int]]], mask_interval: int) -> Tensor:\n",
        "        length = len(input_ids)\n",
        "        tokens: List[str] = self._tokenizer.convert_ids_to_tokens(input_ids)\n",
        "        offset = mask_interval // 2 + 1\n",
        "        mask_count = offset\n",
        "        for i, token in enumerate(tokens):\n",
        "            # Skip initial subword\n",
        "            if i + 1 < length and self._is_subword(tokens[i + 1]): continue\n",
        "            if not self._substitutable_single(token): continue\n",
        "            if mask_count % mask_interval == 0:\n",
        "                input_ids[i] = self._tokenizer.mask_token_id\n",
        "            mask_count += 1\n",
        "        return input_ids\n",
        "\n",
        "    def _predict(self, input_ids: Union[Tensor, List[List[int]]]):\n",
        "        self._model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = self._model(input_ids.unsqueeze(0))['logits'][0]\n",
        "            softmaxed_score = F.softmax(output, dim=1)  # [word_len, vocab_len]\n",
        "            return softmaxed_score.sort(dim=1, descending=True)\n",
        "\n",
        "    def _encode_topk(self, ids: List[int], message: StringIO, bits_per_token: int) -> int:\n",
        "        k = 2**bits_per_token\n",
        "        candidates: List[int] = []\n",
        "        for id in ids:\n",
        "            token = self._tokenizer.convert_ids_to_tokens(id)\n",
        "            if not self._substitutable_single(token):\n",
        "                continue\n",
        "            candidates.append(id)\n",
        "            if len(candidates) >= k:\n",
        "                break\n",
        "        return self._block_encode_single(candidates, message)\n",
        "\n",
        "    def _pick_candidates_threshold(self, ids: Tensor, scores: Tensor, threshold: float) -> List[int]:\n",
        "        filtered_ids: List[int] = ids[scores >= threshold]\n",
        "        def filter_fun(idx: Tensor) -> bool:\n",
        "            return self._substitutable_single(self._tokenizer.convert_ids_to_tokens(idx.item()))\n",
        "        return list(filter(filter_fun, filtered_ids))\n",
        "\n",
        "    def _substitutable_single(self, token: str) -> bool:\n",
        "        if self._is_subword(token): return False\n",
        "        if token.lower() in self._STOPWORDS: return False\n",
        "        if not token.isalpha(): return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def _block_encode_single(ids: List[int], message: StringIO) -> int:\n",
        "        assert len(ids) > 0\n",
        "        if len(ids) == 1:\n",
        "            return ids[0]\n",
        "        capacity = len(ids).bit_length() - 1\n",
        "        bits_str = message.read(capacity)\n",
        "        if len(bits_str) < capacity:\n",
        "            padding: str = '0' * (capacity - len(bits_str))\n",
        "            bits_str = bits_str + padding\n",
        "            message.write(padding)\n",
        "        index = int(bits_str, 2)\n",
        "        return ids[index]\n",
        "\n",
        "    @staticmethod\n",
        "    def _block_decode_single(ids: List[int], chosen_id: int) -> str:\n",
        "        if len(ids) < 2:\n",
        "            return ''\n",
        "        capacity = len(ids).bit_length() - 1\n",
        "        index = ids.index(chosen_id)\n",
        "        return format(index, '0' + str(capacity) +'b')\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_subword(token: str) -> bool:\n",
        "        return token.startswith('##')\n",
        "masked_stego = MaskedStego()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHcy-lGMWAte",
        "outputId": "edc92807-2817-43c8-fa3f-78448dfcb665"
      },
      "outputs": [],
      "source": [
        "#@title Example\n",
        "\n",
        "# print(masked_stego.decode(args.text, args.mask_interval, args.score_threshold))\n",
        "# print(masked_stego(\"The quick brown fox jumps over the lazy dog.\",'010101010101', 3, 0.01))\n",
        "# print(masked_stego.decode(\"The quick red fox jumps over the poor dog.\", 3, 0.01))\n",
        "# print(masked_stego(\"The quick brown fox jumps over the lazy dog. and said boom you lazy dog stay back\",'010101010101', 3, 0.01))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TdQ6lNerHwGG"
      },
      "source": [
        "## Typoceros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hz3JvxNNdW7"
      },
      "outputs": [],
      "source": [
        "from TypocerosJar import JavaJarWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXvmRu2FBqlX",
        "outputId": "a09b72fd-3e98-4cf3-ea12-d43e3636a8be"
      },
      "outputs": [],
      "source": [
        "Typo = JavaJarWrapper()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "icN5UrprJCh6"
      },
      "source": [
        "## Emojer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DKuWj8o1QTQ"
      },
      "outputs": [],
      "source": [
        "LONG_TEXT = \"\"\"Text literals and metacharacters make up this string. The compile function is used to create the pattern.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bkfhgQHnf6A"
      },
      "outputs": [],
      "source": [
        "# https://github.com/huggingface/torchMoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhLb0qgQ82we"
      },
      "outputs": [],
      "source": [
        "# Emojier : Emojier = Emojier\n",
        "from Emojier import Emojier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d72MrhPzJA3",
        "outputId": "6551fb18-6bfa-4bcc-c8e4-4c54ab3c8d8d"
      },
      "outputs": [],
      "source": [
        "tests = 10\n",
        "print(f\"Running {tests} tests\")\n",
        "for i in range(tests):\n",
        "  data = random_bit_stream(60)\n",
        "  # text = 'hi, how are you?'\n",
        "  text = LONG_TEXT\n",
        "  verbose = True\n",
        "  encoded_text,rem = Emojier.encode(text,data,verbose=verbose)\n",
        "  print('rem=',rem)\n",
        "  _, deData = Emojier.decode(encoded_text,verbose=verbose)\n",
        "  deData += rem\n",
        "  print(f'text=\"{text}\"\\n->\\nencoded_text=\"{encoded_text}\" \\ndata=\"{data}\"\\ndeData=\"{deData}\"\\ndata==deData=\"{data==deData}\"')\n",
        "  print(f'ratio={len(data)-len(rem)} / {len(text)}={(len(data)-len(rem)) / len(text)}')\n",
        "  assert data==deData\n",
        "  print('\\n')\n",
        "  print(\"#\"*100)\n",
        "  print('\\n')\n",
        "\n",
        "# 0000"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "trFfVFPYieTF"
      },
      "source": [
        "## Mental Deterministic Bot"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pbY0v-eJJT1J"
      },
      "source": [
        "### Working solution!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJQ82ZyRmfcY"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from typing import Dict, List, Tuple\n",
        "import torch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "ACTION_SPACE = [ 'ask about kids.', \"ask about pets.\", 'talk about work.', \n",
        "               'ask about marital status.', 'talk about travel.', 'ask about age and gender.',\n",
        "        'ask about hobbies.', 'ask about favorite food.', 'talk about movies.', \n",
        "        'talk about music.', 'talk about politics.']\n",
        "\n",
        "@dataclass\n",
        "class Message:\n",
        "    persona: str\n",
        "    text: str\n",
        "\n",
        "class PersonaGPTBot:\n",
        "    def __init__(self, personas:Dict[str, List[str]], action_space=ACTION_SPACE, model_name=\"af1tang/personaGPT\", use_fast=False):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=use_fast)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "        if torch.cuda.is_available():\n",
        "            self.model = self.model.cuda()\n",
        "        if 'Bot' not in personas:\n",
        "          personas['Bot'] = [\"My name is RobotMan\",\"I used to be called cliff steel\",\"I was a Nascar Racer\"]\n",
        "        self.personas = dict()\n",
        "        for k,v in personas.items():\n",
        "          self.personas[k] = self.tokenizer.encode(''.join(['<|p2|>'] + v + ['<|sep|>'] + ['<|start|>']))\n",
        "        self.action_space = action_space\n",
        "        self.dialog_hx = []\n",
        "        \n",
        "    def flatten(self, l):\n",
        "        return [item for sublist in l for item in sublist]\n",
        "\n",
        "    def to_data(self, x):\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cpu()\n",
        "        return x.data.numpy()\n",
        "\n",
        "    def to_var(self, x):\n",
        "        if not torch.is_tensor(x):\n",
        "            x = torch.Tensor(x)\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cuda()\n",
        "        return x\n",
        "    \n",
        "    def generate_next(self,\n",
        "                  bot_input_ids,\n",
        "                  do_sample=False,  # Default to sampling\n",
        "                  top_k=10,         # Default to no top-k sampling\n",
        "                  top_p=.6,        # Default to no top-p sampling\n",
        "                  temperature=1e-5,   # Default temperature\n",
        "                  max_length=1000, # Maximum length of generated message\n",
        "                  pad_token=None   # Token used for padding if pad_token_id is not provided\n",
        "                  ):\n",
        "        pad_token = pad_token if pad_token is not None else self.tokenizer.eos_token_id\n",
        "        \n",
        "        # Generate a full message using the provided model and parameters\n",
        "        full_msg = self.model.generate(\n",
        "            bot_input_ids,\n",
        "            do_sample=do_sample,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            temperature=temperature,\n",
        "            max_length=max_length,\n",
        "            pad_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "        \n",
        "        # Extract the message from the full generated output and return it\n",
        "        msg = self.to_data(full_msg.detach()[0])[bot_input_ids.shape[-1]:]\n",
        "        return msg\n",
        "\n",
        "    \n",
        "    def reply(self,user_input,persona:str = \"Bot\",dialog_hx=None):\n",
        "        # respond to input \n",
        "        dialog_hx= dialog_hx if dialog_hx is not None else self.dialog_hx\n",
        "\n",
        "        # encode the user input\n",
        "        user_inp = self.tokenizer.encode(user_input + self.tokenizer.eos_token)\n",
        "        # append to the chat history\n",
        "        dialog_hx.append(user_inp)\n",
        "\n",
        "        # generate a response while limiting the total chat history to 1000 tokens\n",
        "        bot_input_ids = self.to_var([self.personas[persona] + self.flatten(dialog_hx)]).long()\n",
        "        msg = self.generate_next(bot_input_ids)\n",
        "        response = self.tokenizer.decode(msg, skip_special_tokens=True)\n",
        "        \n",
        "        return response, dialog_hx\n",
        "\n",
        "    def ask(self,action:str,dialog_hx=None):\n",
        "        # respond to input \n",
        "        if isinstance(action, int):\n",
        "          action = self.action_space[action]\n",
        "        dialog_hx= dialog_hx if dialog_hx is not None else self.dialog_hx\n",
        "        action_prefix = self.tokenizer.encode(f'<|act|>{action}<|p1|><|sep|><|start|>')\n",
        "        bot_input_ids = self.to_var([action_prefix + self.flatten(dialog_hx)]).long()\n",
        "        \n",
        "        # generate query conditioned on action\n",
        "        msg = self.generate_next(bot_input_ids)\n",
        "        \n",
        "        query = self.tokenizer.decode(msg, skip_special_tokens=True)\n",
        "        \n",
        "        return query, dialog_hx\n",
        "    \n",
        "    def resume_chat(self, dialog_hx):\n",
        "        self.dialog_hx = dialog_hx\n",
        "    \n",
        "    def converse(self,length, personas:Tuple[str,str], action=None, startMessage:Message=None, dialog_hx=None):\n",
        "        dialog_hx= dialog_hx if dialog_hx is not None else self.dialog_hx\n",
        "        if action is None and startMessage is None:\n",
        "          startMessage = Message(persona=personas[0],text='')\n",
        "        res = ''\n",
        "        responses = []\n",
        "        if action is not None:\n",
        "          res, dialog_hx = self.ask(action,dialog_hx)\n",
        "        else:\n",
        "          res, dialog_hx = self.reply(startMessage.text,startMessage.persona,dialog_hx)\n",
        "        responses.append(Message(text=res,persona=personas[0]))\n",
        "        turn = 1\n",
        "        for i in range(length-1):\n",
        "          res, dialog_hx = self.reply(res,personas[turn],dialog_hx)\n",
        "          responses.append(Message(text=res,persona=personas[turn]))\n",
        "          turn = (turn+1) % 2\n",
        "        \n",
        "        return responses , dialog_hx\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "oxbINN8BpyzH",
        "outputId": "3c11492a-41f8-450e-8841-4127cea0d159"
      },
      "outputs": [],
      "source": [
        "pg = PersonaGPTBot({'Alice':[\"I'm a french girl\",\"I love art\",\"my name is Alice\"],\"Bob\" :[\"I'm a french boy\",\"I love art\",\"my name is Bob\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxoMbH3wmUZv"
      },
      "outputs": [],
      "source": [
        "dia = []\n",
        "res = [Message(persona='Bob',text='Have you Heard? I\\'m getting married!')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HQS1slVV2DP",
        "outputId": "a4790ac0-74ac-4aea-eabd-2e303dafe0bc"
      },
      "outputs": [],
      "source": [
        "print(res[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjUqdCTXERvR",
        "outputId": "670d2ae9-62d3-4d29-813d-3ee0885f0a8f"
      },
      "outputs": [],
      "source": [
        "res, dia = pg.converse(10,('Alice','Bob'),startMessage=res[-1],dialog_hx=dia)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDw_i0bBKXmg"
      },
      "outputs": [],
      "source": [
        "res = None\n",
        "old_res = None\n",
        "for i in range(100):\n",
        "  dia = []\n",
        "  res = [Message(persona='Bob',text='')]\n",
        "  res, dia = pg.converse(10,('Alice','Bob'),startMessage=res[-1],dialog_hx=dia)\n",
        "  if res is not None and old_res is not None and res != old_res:\n",
        "    print('old_res',old_res)\n",
        "    print('res',res)\n",
        "  else:\n",
        "    print(f'test {i} passed!')\n",
        "  old_res = res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j81jFtFilAHT"
      },
      "outputs": [],
      "source": [
        "a = \"\"\"[Message(persona='Alice', text='hi how are you doing'),\n",
        " Message(persona='Bob', text=\"i'm good thanks for asking\"),\n",
        " Message(persona='Alice', text='what do you do for a living'),\n",
        " Message(persona='Bob', text='i am a french boy'),\n",
        " Message(persona='Alice', text='do you have any hobbies'),\n",
        " Message(persona='Bob', text='i like to play sports'),\n",
        " Message(persona='Alice', text='what do you like about sports'),\n",
        " Message(persona='Bob', text=\"they're fun to play\"),\n",
        " Message(persona='Alice', text='do you play often then'),\n",
        " Message(persona='Bob', text='yeah i play soccer a lot')]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH1QMbgrvCRE",
        "outputId": "58021b15-cde3-403c-fecf-99ae850a57bf"
      },
      "outputs": [],
      "source": [
        "pg.ask('ask about sports',[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mapiHunEp6DV"
      },
      "outputs": [],
      "source": [
        "pg.reply(\"hello i'm mary and yes i've a daughter. do you have any children?\",\"Bob\", [[31373, 466, 345, 423, 597, 1751, 286, 534, 898, 30, 50256]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "utLcUrgQJncb"
      },
      "source": [
        "## talk about article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jyxBdE4JtV6"
      },
      "outputs": [],
      "source": [
        "# from transformers import pipeline\n",
        "\n",
        "# # Load the conversational pipeline\n",
        "# chatbot = pipeline(\"conversational\")\n",
        "\n",
        "# # Define the article string\n",
        "# article = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# # Start the conversation\n",
        "# conversation = []\n",
        "# conversation.append(\"Person 1: Hey, have you read this article?\")\n",
        "# conversation.append(\"Person 2: No, what's it about?\")\n",
        "# conversation.append(f\"Person 1: It's about a fox jumping over a dog. Here's the article: {article}\")\n",
        "\n",
        "# # Generate responses to the article\n",
        "# for i in range(5):\n",
        "#     conversation.append(f\"Person 2: {article}\")\n",
        "#     response = chatbot(conversation)[-1][\"generated_text\"]\n",
        "#     conversation.append(f\"Person 1: {response}\")\n",
        "#     conversation.append(f\"Person 2: {response}\")\n",
        "#     article_response = chatbot(conversation)[-1][\"generated_text\"]\n",
        "#     conversation.append(f\"Person 1: {article_response}\")\n",
        "\n",
        "# # Print the conversation\n",
        "# for line in conversation:\n",
        "#     print(line)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g6r0AQp4ChsJ"
      },
      "source": [
        "## Putting it all Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWxoFfxfzu6F",
        "outputId": "db18a304-4d7f-4dbe-f149-0d2741308e6b"
      },
      "outputs": [],
      "source": [
        "#@title Pipe\n",
        "from typing import List, Any, Dict, Callable\n",
        "\n",
        "def pipe(callbacks: List[Callable], config: Dict[str, Any]={}, index=0):\n",
        "    def process_callbacks(state, callbacks: List[Callable], config: Dict[str, Any]={}, index=0):\n",
        "        # Get the current callback\n",
        "        callback = callbacks[index]\n",
        "\n",
        "        # Get the next callback (if exists)\n",
        "        next_callback = None\n",
        "        if index < len(callbacks) - 1:\n",
        "            next_callback = lambda s, c, cf=config: process_callbacks(s, callbacks, cf, index + 1)\n",
        "\n",
        "        # Call the callback with the current state, next callback, and config\n",
        "        state = callback(state, next_callback, config)\n",
        "\n",
        "        # Return the final state\n",
        "        return state\n",
        "\n",
        "    def _pipe(state):\n",
        "        return process_callbacks(state, callbacks, config, index)\n",
        "\n",
        "    return _pipe\n",
        "\n",
        "def bert_callback(state, next_callback, config):\n",
        "    if state is None:\n",
        "        raise ValueError('State is None')\n",
        "    \n",
        "    pipe_verbose = config['pipe_verbose']\n",
        "    encode = config['encode']\n",
        "    decode = config['decode']\n",
        "    message_pipe, bytes_pipe = state\n",
        "    \n",
        "    if encode:\n",
        "      stega_bert = masked_stego(message_pipe[-1],bytes_pipe[-1], 3, 0.01)\n",
        "      message_pipe.append(stega_bert.encoded_text)\n",
        "      bytes_pipe.append(stega_bert.remaining_bytes)\n",
        "\n",
        "    if next_callback is not None:\n",
        "        state = next_callback(state, next_callback, config)\n",
        "\n",
        "    if decode:\n",
        "      encoded_text = message_pipe.pop() \n",
        "      remaining_bytes = bytes_pipe.pop() \n",
        "      encoded_bytes = masked_stego.decode(encoded_text,3,0.01)\n",
        "      if encode and decode:\n",
        "        assert encoded_bytes + remaining_bytes == bytes_pipe[-1]\n",
        "      else:\n",
        "        message_pipe.append(encoded_text)\n",
        "        bytes_pipe.append(encoded_bytes + remaining_bytes)\n",
        "    \n",
        "    return state\n",
        "\n",
        "def emojer_callback(state, next_callback, config):\n",
        "    if state is None:\n",
        "        raise ValueError('State is None')\n",
        "    \n",
        "    message_pipe, bytes_pipe = state\n",
        "    text = message_pipe[-1]\n",
        "    data = bytes_pipe[-1]\n",
        "    verbose = config['verbose']\n",
        "    \n",
        "    pipe_verbose = config['pipe_verbose']\n",
        "    encode = config['encode']\n",
        "    decode = config['decode']\n",
        "\n",
        "    if encode:\n",
        "      encoded_text,rem = Emojier.encode(text,data,verbose=verbose)\n",
        "      message_pipe.append(encoded_text)\n",
        "      bytes_pipe.append(rem)\n",
        "\n",
        "    if next_callback is not None:\n",
        "        state = next_callback(state, next_callback, config)\n",
        "    else:\n",
        "      print(state)\n",
        "\n",
        "    if decode:\n",
        "      encoded_pipe_text = message_pipe.pop()\n",
        "      rem_pipe_bytes = bytes_pipe.pop()\n",
        "\n",
        "      original_text, deData = Emojier.decode(encoded_pipe_text,verbose=verbose)\n",
        "      deData += rem_pipe_bytes\n",
        "      if encode and decode:\n",
        "        assert deData == bytes_pipe[-1]\n",
        "        assert original_text == message_pipe[-1]\n",
        "      else:\n",
        "        message_pipe.append(original_text)\n",
        "        bytes_pipe.append(deData)\n",
        "    \n",
        "    return state\n",
        "\n",
        "def typo_callback(state, next_callback, config):\n",
        "    if state is None:\n",
        "        raise ValueError('State is None')\n",
        "    \n",
        "    message_pipe, bytes_pipe = state\n",
        "    text = message_pipe[-1]\n",
        "    data = bytes_pipe[-1]\n",
        "    verbose = config['verbose']\n",
        "    pipe_verbose = config['pipe_verbose']\n",
        "    encode = config['encode']\n",
        "    decode = config['decode']\n",
        "\n",
        "    if pipe_verbose:\n",
        "      print(state)\n",
        "    if encode:\n",
        "\n",
        "      encoded_text, rem = Typo.encode(text,data) \n",
        "      \n",
        "      message_pipe.append(encoded_text)\n",
        "      bytes_pipe.append(rem)\n",
        "\n",
        "    if next_callback is not None:\n",
        "        state = next_callback(state, next_callback, config)\n",
        "\n",
        "    if decode :\n",
        "      encoded_pipe_text = message_pipe.pop()\n",
        "      rem_pipe_bytes = bytes_pipe.pop()\n",
        "\n",
        "      original_string, values = Typo.decode(encoded_pipe_text)\n",
        "      if encode and decode:\n",
        "        assert original_string == text\n",
        "        assert values == data\n",
        "      else:\n",
        "        message_pipe.append(original_string)\n",
        "        bytes_pipe.append()\n",
        "    \n",
        "    \n",
        "    return state\n",
        "\n",
        "callbacks = [bert_callback, emojer_callback,typo_callback]\n",
        "# callbacks = [typo_callback]\n",
        "\n",
        "# Apply the function with an initial state\n",
        "initial_state = [['Hi, How are you?'],[random_bit_stream(30)]]\n",
        "p = pipe(callbacks, {\"verbose\": False,\"pipe_verbose\": False,\"encode\":True,\"decode\":False,\"test\":False})\n",
        "mq, bq = p(initial_state)\n",
        "\n",
        "print(mq[-1],bq[-1]) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DbJ101XFbKa"
      },
      "outputs": [],
      "source": [
        "# PersonaGPTBot_Singleton = PersonaGPTBot({'Alice':[\"I'm a french girl\",\"I love art\",\"my name is Alice\"],\"Bob\" :[\"I'm a french boy\",\"I love art\",\"my name is Bob\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNnH7AK-YIgX"
      },
      "outputs": [],
      "source": [
        "def StegasusEncode(text,bytes_str):\n",
        "  initial_state = [[text],[bytes_str]]\n",
        "  callbacks = [bert_callback, emojer_callback,typo_callback]\n",
        "  p = pipe(callbacks, {\"verbose\": False,\"pipe_verbose\": False,\"encode\":True,\"decode\":False,\"test\":False})\n",
        "  mq, bq = p(initial_state)\n",
        "  return (mq[-1],bq[-1]) \n",
        "\n",
        "def StegasusDecode(text):\n",
        "  initial_state = [[text],['']]\n",
        "  callbacks = [bert_callback, emojer_callback,typo_callback]\n",
        "  p = pipe(callbacks, {\"verbose\": False,\"pipe_verbose\": False,\"encode\":False,\"decode\":True,\"test\":False})\n",
        "  mq, bq = p(initial_state)\n",
        "  return (mq[-1],bq[-1]) \n",
        "  \n",
        "\n",
        "def StegasusTest(text):\n",
        "  initial_state = [[text],[random_bit_stream(len(text))]]\n",
        "  callbacks = [bert_callback, emojer_callback,typo_callback]\n",
        "  p = pipe(callbacks, {\"verbose\": False,\"pipe_verbose\": False,\"encode\":False,\"decode\":True,\"test\":False})\n",
        "  mq, bq = p(initial_state)\n",
        "  return (mq[-1],bq[-1]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUNaP0tPHnI4"
      },
      "outputs": [],
      "source": [
        "LONG_TEXT = '''Metaphysical solipsism is a variety of solipsism. Based on a philosophy of subjective idealism, metaphysical solipsists maintain that the self is the only existing reality and that all other realities, including the external world and other persons.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtZsf0z7hLt-"
      },
      "outputs": [],
      "source": [
        "Famous_Demo = 'Hi, How are you?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWQFFntewLUX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# xtx = LONG_TEXT\n",
        "xtx = Famous_Demo\n",
        "data = random_bit_stream(len(xtx))\n",
        "returned = StegasusEncode(xtx,data)\n",
        "print(returned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbjmDyO0E9qL",
        "outputId": "ef7aa058-ada2-4f05-a6d4-78bf0de5eec5"
      },
      "outputs": [],
      "source": [
        "(len(xtx) - len(returned[1])) / len(xtx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Bot import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## OpenAi\n",
        "#@title askGPT\n",
        "import openai\n",
        "import re\n",
        "demo_post = re.sub(r'\\s+', ' ', \"\"\"235r/ExperiencedDevs•Posted byu/EcstaticAssignment12 hours agoThe backend generalist software engineer\n",
        "              \n",
        "            I think both myself and a lot of my coworkers/friends fall under this category of \"backend non web-dev stack agnostic generalist software engineer\" that seem to hang out in product companies.While I've gotten experience in domains by virtue of the teams and projects I've worked with, I wouldn't really identify them as being my \"specialty\". I've also never really identified with my tech stack, both because it changes a lot and because frankly the complexity of my work never seems to boil down to low level implementation expertise. There are almost never any serious design meetings where the main point of contention is anything that is on the layer of programming patterns or language details (but obviously yes to system design). The problems that I mainly solve seem to be more \"engineering\" than programming, and while I'd say they are complex, they seem to be mostly a function of general analytical reasoning and more system design-level understanding.Is this sort of position actually that common outside of tech companies? I'm asking mostly out of curiosity, but also while I was lucky to land in another tech company after getting laid off in January, if I get laid off again and don't have the same luck, I'm not sure if I should take steps to brand myself as something less generalist when exploring other options.51 commentsAwardsharesave22 people hereu/getsentry·promotedPaste this line into your terminal to use Next.js with Sentry.\n",
        "              \n",
        "            sentry.ioInstallComment as No_Door_3720CommentBoldItalicsLinkStrikethroughInline CodeSuperscriptSpoilerHeadingBulleted ListNumbered ListQuote BlockCode BlockTableMarkdown ModeSort by: best|\n",
        "                \n",
        "              level 1_sw00 · 10 hr. agoLead Developer | 11 YOEGeneralist who works on higher level design, development practices and techniques?Welcome to consulting, brother/sister.156ReplyGive AwardShareReportSaveFollowlevel 2rkeet · 8 hr. agoLead Application Engineer / 9 YoE / NLDCan I... Bother you for some tips? ;)OP sounds like me, and I'm looking into different applicable jobs at this moment.So, I'll take any hints, options, etc. as to what to look at, because I don't know whether to look at Lead Developer, Solution Architect, Facility Manager, Integration/service consultant, or how to find a mix.Bit of a problem when I like what I do. Just not where I do it.20ReplyGive AwardShareReportSaveFollowlevel 2bwainfweeze · 3 hr. agolevel 2mrcrassic · 5 hr. agoYup! Exactly where I landed.2ReplyGive AwardShareReportSaveFollowlevel 1d0s4gw · 7 hr. agoAny given system is not supposed to have a high degree of technical complexity. The point of being a senior or staff engineer is to enable juniors and mid level engineers to deliver impact quickly with low risk. If the system is easy to extend and operate then that’s because the people that designed it did a good job.Your job is to quickly translate vague information into clear requirements into shipped code. No one cares which data structures was used when you recovered $50m a year in opex. Your resume should explain the value that you delivered. The tech stack is ancillary.33ReplyGive AwardShareReportSaveFollowlevel 2cjrun · 4 hr. agoProblem is, if you don’t have those buzzwords on your résumé, even the hiring manager won’t be interested.6ReplyGive AwardShareReportSaveFollowlevel 3d0s4gw · 3 hr. agoYea exactly. But it’s at the end of the block on the resume. It’s not the top line. The focus is the business result.Senior Software Engineer, Company, City, State (Start date - End date)Technical lead for the <name of service>, which <achieved X quantitative result> for <customer type> by <method of solving the problem>distributed systems, Java, SQL, AWS, S3, Linux, and Bash3ReplyGive AwardShareReportSaveFollowlevel 1GargantuChet · 10 hr. agoThis sounds like a joy to me. This describes my role in a big manufacturer, and most of the time I feel like I’m the only one on the planet.Mind if I PM?64ReplyGive AwardShareReportSaveFollowlevel 2EcstaticAssignmentOp · 10 hr. agohaha go for it4ReplyGive AwardShareReportSaveFollowlevel 2bizcs · 3 hr. agoI also work for a manufacturer in this sort of role, though. I consider us to be large but others from megalith manufacturers might beg to differ.1ReplyGive AwardShareReportSaveFollowlevel 1gabs_ · 10 hr. agoI also fit in this category! I'm only a mid-level developer, but I have worked at tech companies previously and I'm now developing a Big Data project at a logistics company.9ReplyGive AwardShareReportSaveFollowlevel 1Inside_Dimension5308 · 8 hr. agoI always advocate the backend generalist software engineer. Tech stacks are replaceable. Knowledge to determine which tech stack to use will be eternal.8ReplyGive AwardShareReportSaveFollowlevel 1nutrecht · 8 hr. agoLead Software Engineer / EU / 18+ YXPThe problem with being a generalist is that, if you're not careful, your experience remains very shallow. You can end up not having 10 years of experience, but 1 year repeated 10 times.For the most part  my 'brand' as a self employed contractor who focusses on the Java ecosystem doesn't have much to do with Java itself, but more with the type of work I do. I focus on complex enterprise systems, often with a ton of different systems interacting, and providing my clients with deep expertise in how to not turn those into big balls of mud. If you're mostly doing the same simple back-end projects (like in wordpress as an extreme example) you don't get that experience.So I don't agree that what you're describing is 'good' or 'bad'. It really depends on how you plan and advance your career. For example as this generalist if you don't now have cloud-native experience you're IMHO falling behind the curve.28ReplyGive AwardShareReportSaveFollowlevel 1ir0nuckles · 6 hr. agoThere are almost never any serious design meetings where the main point of contention is anything that is on the layer of programming patterns or language details (but obviously yes to system design). The problems that I mainly solve seem to be more \"engineering\" than programming, and while I'd say they are complex, they seem to be mostly a function of general analytical reasoning and more system design-level understanding.I'm confused. Isn't this what being a software engineer is?I've never done \"design reviews\" of programming patterns. That's for a code review, or if needed, you can engage your team before you start a project to ensure you're following best practices.This post is really strange to me. If you're asking \"how do I prepare my skillset for find a job outside of tech\" then I would suggest you become really good cloud computing platforms and patterns. Almost every enterprise is using a cloud provider at this point. If you're the expert in AWS, GCP, or Azure, you're probably guaranteed to find some work somewhere in the world working with one of these platforms.4ReplyGive AwardShareReportSaveFollowlevel 1FlutterLovers · 10 hr. agoGeneralist will make you a better engineer, but focus will get you hired. Try to become an expert at one backend framework that is currently in demand, while also learning the basics of adjacent systems.30ReplyGive AwardShareReportSaveFollowlevel 2chrismv48 · 9 hr. agoWhenever I hear this sentiment I feel confused; all the best tech companies I’m aware of are explicitly tech agnostic (FAANG as well as best paying startups). It’s the companies that insist on having experience in a very specific stack that tend to pay poorly in my experience. What am I missing?72ReplyGive AwardShareReportSaveFollowlevel 3Successful_Leg_707 · 8 hr. agoMy understanding is the specific tech stack companies tend to “hire when it hurts”.  They want someone already up to speed on a language and framework in demand.  They are less willing to gamble on long term potential.  You get a salary but no RSU to retain you.Tech agnostic companies hire for long term potential and projected growth.  Amazon for example will use a language like Java but develop their own in house framework, so knowledge in a specific framework like Spring is less useful.  The tech companies will have some sort of leetcode interview process that is an indicator for general cognitive ability and fundamental comp sci concepts.  On top of a base salary, you get the RSUs which are like golden handcuffs that encourage you to stay until they vest41ReplyGive AwardShareReportSaveFollowlevel 4generatedcode · 8 hr. agotech stack companies tend to “hire when it hurts”.you deserve an award !18ReplyGive AwardShareReportSaveFollowlevel 4EcstaticAssignmentOp · 3 hr. agoTech agnostic companies hire for long term potential and projected growth.I think this trend may be part of the picture, but I'm not sure if it's the full picture. The top startups also tend to hire the \"general cognitive ability + fundamentals\" way, despite having the same short timeline requirements, while some legacy companies that tend to have longer tenures hire the more specific way. It's possible it's more a function of a higher hiring bar tending to correlate with the agnostic approach, whichever way that causation goes.1ReplyGive AwardShareReportSaveFollowlevel 3Acidic-Soil · 8 hr. agolevel 2ExistentialDroid23 · 9 hr. agoI see those claims like \"generalists are better engineers\" but I don't see the connection. Wouldn't diving to one language/framework deep for 2-3 years give you a deeper understanding that you carry around easier later than fumbling 2-3 frameworks on the same timeframe?I guess what I dislike is the equivalency of \"more languages = better engineer\" when in fact what matters is the proper use of the tool, not necessarily how many tools you have.3ReplyGive AwardShareReportSaveFollowlevel 3slightly_offtopic · 9 hr. agoEach language/framework has a preference for a certain way of solving problems. Learning several tools is a proxy for learning sev\"\"\")\n",
        "\n",
        "\n",
        "bob = Person(first_name='Bob Doe', gender='male',age=13,city='France') \\\n",
        "  .add_favorite('color','blue') \\\n",
        "  .add_interest('travelling') \\\n",
        "  .add_favorite('dog','Pitbull') \n",
        "alice = Person(first_name='alice wonderland', gender='girl',age=13,city='France') \\\n",
        "  .add_favorite('color','pink') \\\n",
        "  .add_interest('fashon') \\\n",
        "  .add_favorite('dog','Corgie') \n",
        "  \n",
        "\n",
        "\n",
        "def askGPT(text):\n",
        "  openai.api_key = \"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\"\n",
        "  response = openai.Completion.create(\n",
        "    engine = \"text-davinci-003\",\n",
        "    prompt = text,\n",
        "    temperature = 0.6,\n",
        "    max_tokens = 150,\n",
        "  )\n",
        "  return response.choices[0].text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat = Chat(alice,bob,askGPT)\n",
        "\n",
        "chat.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat.messages\n",
        "\n",
        "data = random_bit_stream(10000)\n",
        "\n",
        "for m in chat.stream():\n",
        "  enc,rem = StegasusEncode(m.text,data) \n",
        "  print(enc,rem)\n",
        "  data = rem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "10000 - len(\"1011010001111000110010001001100101111001101001100101011101100100110011101101000100101011001111010110010100010110010000000011111000001001000001010000111000111000110001010001011001001000000001110100001011110111010110010101110000101000000010000000101101001001001001101100110000011011010001001100100110111111000001110101110001101010001010100100101011010000111111110110100011110011011010011000111100110111011000000101011000110111101010101001111110101001100110010111111010001110111000001010110101001111111011101001101110001110011000110100010001111100110010011001011110101001011111011100011000001011000000011101100110000101001001011110100000100100010010011001010001111011101111001110111110000000001111111011010010010110000000100111000111100111110010010000110110100010101011010000000010001100110010110010100000110011100111001010100110101111111101000101010001111000101101100110100\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ODi5968TKDdR",
        "Dy9bCvx4G9KS",
        "xfisFBGLfQo6",
        "kYBmlY9oLT2m",
        "TdQ6lNerHwGG",
        "icN5UrprJCh6",
        "JQRmozHXHHDS",
        "qXD3IGdrc9fY",
        "trFfVFPYieTF",
        "utLcUrgQJncb"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "047b371312144b4a8897da91d2529ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aa220ee6d564e4e915863e1f4a29d5b",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7ff1d841ffe479cbf35b2deecd41e3e",
            "value": 150
          }
        },
        "0ba42ceb8f904a7280aace5e38b5a7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a6300f40c444098123a8ab3b7aa5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_cf999f9855f74bfdb42238d9e5ccb376",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "0dc38a39a3f14b2794b6538578697af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ba42ceb8f904a7280aace5e38b5a7e5",
              "IPY_MODEL_047b371312144b4a8897da91d2529ed3",
              "IPY_MODEL_a4ba6d87263744c39f3320a93c48a0d9"
            ],
            "layout": "IPY_MODEL_a0978b5e28a6443e90118f21fda45325"
          }
        },
        "112c72841ee14ce0b3396bd089491d77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13001f916e98452099f71bc6cd52511c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19557014c7534f2287828f45131a7837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4174780ddab47ad8ef83bbf9ae64b93",
            "placeholder": "​",
            "style": "IPY_MODEL_6f9b1784efff479dab7c5019f29a293e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "1d6fb228f1db4660a1c85588de5f5e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bb14185a8214e70ab99e9e01cb85cf5",
            "placeholder": "​",
            "style": "IPY_MODEL_47cd3188028c4ae0b7ce0d612993aa99",
            "value": " 899k/899k [00:00&lt;00:00, 11.1MB/s]"
          }
        },
        "22cb62534bff460ebfa0e68b48e2876f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "232b800ae6bf489ea9a893f21fe4f9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f77f65396c41d08a07aea099f078fa",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f36ec65cc939493b84bd4d7f1a9b98b9",
            "value": 898822
          }
        },
        "24a6300f40c444098123a8ab3b7aa5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "358b4bb7eb4b4a50bf784830c281ae17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa220ee6d564e4e915863e1f4a29d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eccd60c4c714486a412b22478faf781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a21244a87642a58ee5f0655d7857c8",
            "placeholder": "​",
            "style": "IPY_MODEL_747185974aea48f8bd9577d57a097dda",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "401cf546de3647f9b2661ad438524776": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f7ae6010fb4d0f808a36f61b8fed63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47bfd2dd60754c04b21f726a1ee585bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb82416bc84475da0d8882ff54d1cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_f513253d7a084ec4a83d180d94492d4f",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "47cd3188028c4ae0b7ce0d612993aa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "484cd4bb0b0e4e348d6074f21da78684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e45ed7d88654b5b97f958c17ac23eac",
            "placeholder": "​",
            "style": "IPY_MODEL_64f7f01515924522a5b6fd44e31af843",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "4a6d5e6788d549108e0c1e14d1a82535": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb14185a8214e70ab99e9e01cb85cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51360a9b9cfd4a6da0dd323f21531bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7da392f99e74930ad620cc295365dfb",
            "max": 1291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13001f916e98452099f71bc6cd52511c",
            "value": 1291
          }
        },
        "55a21244a87642a58ee5f0655d7857c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6345aaabf0724e34b215ca1c1d21c19f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f7f01515924522a5b6fd44e31af843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65f77f65396c41d08a07aea099f078fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6908654c217f4ae8825ea8f8a661857a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f9b1784efff479dab7c5019f29a293e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "747185974aea48f8bd9577d57a097dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "786a392f477c4f81ab6cecda7a0ca69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa39df2250d642dab5c2b10885b9485f",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d05ef7d71e4d85aee9f5b5a72e1870",
            "value": " 499M/499M [00:03&lt;00:00, 124MB/s]"
          }
        },
        "7e45ed7d88654b5b97f958c17ac23eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91aa04b34bc746edb0db0d630478b839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_112c72841ee14ce0b3396bd089491d77",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8ab87ecc439428f81a3e14f0f6d3fae",
            "value": 456318
          }
        },
        "975e43e5ea9549b282aa0e010ea02045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0978b5e28a6443e90118f21fda45325": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d05ef7d71e4d85aee9f5b5a72e1870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4ba6d87263744c39f3320a93c48a0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401cf546de3647f9b2661ad438524776",
            "placeholder": "​",
            "style": "IPY_MODEL_6908654c217f4ae8825ea8f8a661857a",
            "value": " 150/150 [00:00&lt;00:00, 7.08kB/s]"
          }
        },
        "a55f4e3a1d56420ea4a7a6153be6eba3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af42ef08c4974d059bcb47a217281121": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a55f4e3a1d56420ea4a7a6153be6eba3",
            "placeholder": "​",
            "style": "IPY_MODEL_22cb62534bff460ebfa0e68b48e2876f",
            "value": " 456k/456k [00:00&lt;00:00, 6.56MB/s]"
          }
        },
        "bb42525fea1647348197f9efe392e74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19557014c7534f2287828f45131a7837",
              "IPY_MODEL_51360a9b9cfd4a6da0dd323f21531bae",
              "IPY_MODEL_ed3418a3dbba4e33a3c93fd18b82ab54"
            ],
            "layout": "IPY_MODEL_6345aaabf0724e34b215ca1c1d21c19f"
          }
        },
        "c5cafa58674d4214a072b235c7064397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_484cd4bb0b0e4e348d6074f21da78684",
              "IPY_MODEL_d7c5c188bc7544329497fc5abe44366e",
              "IPY_MODEL_786a392f477c4f81ab6cecda7a0ca69d"
            ],
            "layout": "IPY_MODEL_4a6d5e6788d549108e0c1e14d1a82535"
          }
        },
        "cf999f9855f74bfdb42238d9e5ccb376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfc4af49c6f84b01bc45f7007fcde890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c5c188bc7544329497fc5abe44366e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ab5d9a0db24d7f84e95099cf50bc63",
            "max": 498731785,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_975e43e5ea9549b282aa0e010ea02045",
            "value": 498731785
          }
        },
        "d7ff1d841ffe479cbf35b2deecd41e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9ab5d9a0db24d7f84e95099cf50bc63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4174780ddab47ad8ef83bbf9ae64b93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6493d67c8c047259747fe6150663966": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ab87ecc439428f81a3e14f0f6d3fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecb2b58d042a488eb77a4d6074ff2b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47bfd2dd60754c04b21f726a1ee585bf",
              "IPY_MODEL_91aa04b34bc746edb0db0d630478b839",
              "IPY_MODEL_af42ef08c4974d059bcb47a217281121"
            ],
            "layout": "IPY_MODEL_358b4bb7eb4b4a50bf784830c281ae17"
          }
        },
        "ed3418a3dbba4e33a3c93fd18b82ab54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfc4af49c6f84b01bc45f7007fcde890",
            "placeholder": "​",
            "style": "IPY_MODEL_e6493d67c8c047259747fe6150663966",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "f36ec65cc939493b84bd4d7f1a9b98b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f420a6c0793b4c66addb8db83199ec9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3eccd60c4c714486a412b22478faf781",
              "IPY_MODEL_232b800ae6bf489ea9a893f21fe4f9be",
              "IPY_MODEL_1d6fb228f1db4660a1c85588de5f5e71"
            ],
            "layout": "IPY_MODEL_44f7ae6010fb4d0f808a36f61b8fed63"
          }
        },
        "f513253d7a084ec4a83d180d94492d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7da392f99e74930ad620cc295365dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa39df2250d642dab5c2b10885b9485f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb82416bc84475da0d8882ff54d1cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
