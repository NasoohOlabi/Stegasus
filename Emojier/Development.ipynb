{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOONG_TEXT = \"\"\"Text literals and metacharacters make up this string. The compile function is used to create the pattern.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "from util import StringSpans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title random_bit_stream\n",
    "import random\n",
    "\n",
    "def random_bit_stream(length=None):\n",
    "    \"\"\"Return a random string of zeros and ones of the given length (default: random integer between 0 and 100).\"\"\"\n",
    "    if length is None:\n",
    "        length = random.randint(0, 100)\n",
    "    return ''.join(str(random.randint(0, 1)) for _ in range(length))\n",
    "def int_to_binary_string(n: int, length: int):\n",
    "    binary_str = bin(n)[2:]  # convert to binary string, remove '0b' prefix\n",
    "    padded_str = binary_str.rjust(length, '0')  # pad with zeros to length\n",
    "    return padded_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title https://github.com/farkmarnum/emojify\n",
    "import json\n",
    "import random\n",
    "from math import log2,floor \n",
    "import itertools\n",
    "import re\n",
    "from typing import Dict, Generator, List, Tuple\n",
    "\n",
    "with open('./emoji-data.json', 'r') as f:\n",
    "    emoji_data: Dict[str,Dict[str,List[str]]] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Constants\n",
    "regex = re.compile(r'[a-z0-9]+')\n",
    "ALL_EMOJIS = set()\n",
    "for k,v in emoji_data.items():\n",
    "  if regex.match(k) is None:\n",
    "    ALL_EMOJIS.add(k)\n",
    "    # print('k',k)\n",
    "  if isinstance(v,str) and regex.match(v) is None:\n",
    "    ALL_EMOJIS.add(v)\n",
    "    # print('v',v)\n",
    "  else:\n",
    "    for kk,vv in v.items():\n",
    "      if regex.match(kk) is None:\n",
    "        ALL_EMOJIS.add(kk)\n",
    "        # print('kk',kk)\n",
    "      if isinstance(vv,str) and regex.match(vv) is None:\n",
    "        ALL_EMOJIS.add(v)\n",
    "        # print('vv',vv)\n",
    "EMOJIER_COMMON_WORDS = {\n",
    "    'a',\n",
    "    'an',\n",
    "    'as',\n",
    "    'is',\n",
    "    'if',\n",
    "    'of',\n",
    "    'the',\n",
    "    'it',\n",
    "    'its',\n",
    "    'or',\n",
    "    'are',\n",
    "    'this',\n",
    "    'with',\n",
    "    'so',\n",
    "    'to',\n",
    "    'at',\n",
    "    'was',\n",
    "    'and',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10000 tests\n",
      "avg ration = 0.8235294117648159\n"
     ]
    }
   ],
   "source": [
    "#@title encode decode\n",
    "class Emojier:\n",
    "  @staticmethod\n",
    "  def gaussian_order(lst):\n",
    "    length = len(lst)\n",
    "    max_odd_ind = length - 1 if length % 2 == 0 else length - 2\n",
    "    max_even_ind = length - 1 if length % 2 != 0 else length - 2\n",
    "    dist = itertools.chain(range(max_odd_ind,0,-2),range(0,max_even_ind + 1 , 2))\n",
    "    return [lst[i] for i in dist]\n",
    "\n",
    "  @staticmethod\n",
    "  def encode(input_str: str, bytes_str: str, verbose=False) -> Tuple[str,str]:\n",
    "    if verbose:\n",
    "      print('encode:')\n",
    "    input_str_spans = StringSpans(input_str)\n",
    "    word_span_n_words = zip(input_str_spans.words, input_str_spans.get_words())\n",
    "    result = input_str\n",
    "    acc_offset = 0\n",
    "    for (_,we), word_raw in word_span_n_words:\n",
    "      word = word_raw.lower()\n",
    "      is_too_common = word in EMOJIER_COMMON_WORDS\n",
    "\n",
    "      emoji_options = \\\n",
    "        Emojier.gaussian_order( ['']+\n",
    "          [x[0] for x in\n",
    "            sorted(\n",
    "              emoji_data.get(word, {}).items(),\n",
    "              key=lambda x:x[1],\n",
    "              reverse=True\n",
    "            )\n",
    "          ]\n",
    "        )\n",
    "\n",
    "      if verbose:\n",
    "        print(f\"word: {word} \\tis_too_common={is_too_common} \\nlen: {len(emoji_options)} \\temoji_options[:10]: {emoji_options[:10]}\")\n",
    "\n",
    "      if not is_too_common and len(emoji_options)>=2:\n",
    "        bits = floor(log2(len(emoji_options)))\n",
    "        taken_bits = bytes_str[:bits]\n",
    "        ind = int(taken_bits, 2)\n",
    "        bytes_str = bytes_str[bits:]\n",
    "        emojis = emoji_options[ind]\n",
    "        if len(emojis) > 0:\n",
    "          we = we + acc_offset\n",
    "          acc_offset += len(emojis) + 1\n",
    "          if verbose:\n",
    "            print(f'>>>encoding {taken_bits} = {ind} as {emojis}\\nwe={we}\\tacc_offset={acc_offset}')\n",
    "            print(f'result[:we]=\"{result[:we]}\" result[we:]=\"{result[we:]}\"')  \n",
    "          result = f'{result[:we]} {emojis}{result[we:]}'  \n",
    "\n",
    "    return result, bytes_str\n",
    "\n",
    "  @staticmethod\n",
    "  def eat_back(s:str) -> Generator[str,None,None]:\n",
    "    for i in range(len(s),-1,-1):\n",
    "      yield s[0:i]\n",
    "  @staticmethod\n",
    "  def decode(input_str: str, verbose=False) -> Tuple[str,str]:\n",
    "    if verbose:\n",
    "      print('decoding!')\n",
    "    wordish = re.compile(r'^[a-z]*$')\n",
    "    input_str_ss = StringSpans(input_str)\n",
    "    words = [input_str[s:e] for s,e in input_str_ss.non_spaces]\n",
    "    result = input_str\n",
    "    bytes_str = ''\n",
    "    \n",
    "    emoticons_used = []\n",
    "    for i, word_raw in enumerate(words[:-1]):\n",
    "      word = word_raw.lower()\n",
    "      \n",
    "      if wordish.match(word) is None:\n",
    "        continue \n",
    "\n",
    "      is_too_common = word in EMOJIER_COMMON_WORDS\n",
    "\n",
    "      emoji_options = \\\n",
    "        Emojier.gaussian_order( ['']+\n",
    "          [x[0] for x in\n",
    "            sorted(\n",
    "              emoji_data.get(word, {}).items(),\n",
    "              key=lambda x:x[1],\n",
    "              reverse=True\n",
    "            )\n",
    "          ]\n",
    "        )\n",
    "\n",
    "      if verbose:\n",
    "        print(f\"word: {word} \\tis_too_common={is_too_common} \\nlen: {len(emoji_options)} \\temoji_options[:10]: {emoji_options[:10]}\")\n",
    "\n",
    "      if not is_too_common and len(emoji_options)>=2:\n",
    "        bits = floor(log2(len(emoji_options)))\n",
    "        index = 0\n",
    "        for w in Emojier.eat_back(words[i+1]):\n",
    "          if w in emoji_options:\n",
    "            index = emoji_options.index(w)\n",
    "            emoticons_used.append((w,i+1))\n",
    "            break\n",
    "          \n",
    "        data_extracted = int_to_binary_string(index,bits)\n",
    "        if verbose:\n",
    "          print(f'>>>decoding word:\"{words[i]}\" next word:\"{words[i+1]}\" length:\"{len(emoji_options)}\"')\n",
    "          print(f'bits:\"{bits}\" data extracted:\"{data_extracted}\" index:\"{index}\"')\n",
    "        bytes_str += data_extracted\n",
    "    for emo,idx in reversed(emoticons_used):\n",
    "      s,e = input_str_ss.non_spaces[idx]\n",
    "      if emo:\n",
    "        result = result[:s-1] + result[s:e].replace(emo,'') + result[e:]\n",
    "  \n",
    "    return result, bytes_str\n",
    "\n",
    "\n",
    "tests = 10000\n",
    "sum = 0\n",
    "onlyRatio = True\n",
    "print(f\"Running {tests} tests\")\n",
    "for i in range(tests):\n",
    "  data = random_bit_stream(60)\n",
    "  # text = 'hi, how are you?'\n",
    "  text = 'Hi, how are you?\\n'\n",
    "  verbose = False\n",
    "  encoded_text,rem = Emojier.encode(text,data,verbose=verbose)\n",
    "  if not onlyRatio:\n",
    "    print('rem=',rem)\n",
    "    print('encoded_text=',encoded_text)\n",
    "  original_txt, deData = Emojier.decode(encoded_text,verbose=verbose)\n",
    "  if not onlyRatio:\n",
    "    print('original_txt=',original_txt)\n",
    "  deData += rem\n",
    "  if not onlyRatio:\n",
    "    print(f'text=\"{text}\"\\n->\\nencoded_text=\"{encoded_text}\" \\ndata=\"{data}\"\\ndeData=\"{deData}\"\\ndata==deData=\"{data==deData}\"')\n",
    "  ratio =(len(data)-len(rem)) / len(text)\n",
    "  sum += ratio\n",
    "  if not onlyRatio:\n",
    "    print(f'ratio={len(data)-len(rem)} / {len(text)}={ratio}')\n",
    "  assert data==deData\n",
    "  assert text==original_txt\n",
    "  if not onlyRatio:\n",
    "    print('\\n')\n",
    "    print(\"#\"*100)\n",
    "    print('\\n')\n",
    "\n",
    "print(f'avg ratio = {sum/tests}')\n",
    "\n",
    "# 0000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
