{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LONG_TEXT = \"\"\"Text literals and metacharacters make up this string. The compile function is used to create the pattern.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.insert(0, parent_dir)\n",
        "from StringSpans import StringSpans\n",
        "from SemanticMasking import MaskGen, SemanticPositions\n",
        "import itertools\n",
        "from icecream import ic\n",
        "import csv\n",
        "import itertools\n",
        "import re\n",
        "import urllib.request\n",
        "from math import floor, log2,inf\n",
        "from typing import Any, Generator, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from icecream import ic\n",
        "from scipy.special import softmax  # type: ignore\n",
        "from transformers import AutoModelForSequenceClassification  # type: ignore\n",
        "from transformers import AutoTokenizer  # type: ignore\n",
        "from transformers import TFAutoModelForSequenceClassification  # type: ignore\n",
        "\n",
        "from SemanticMasking import MaskGen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title random_bit_stream\n",
        "import random\n",
        "\n",
        "def random_bit_stream(length=None):\n",
        "    \"\"\"Return a random string of zeros and ones of the given length (default: random integer between 0 and 100).\"\"\"\n",
        "    if length is None:\n",
        "        length = random.randint(0, 100)\n",
        "    return ''.join(str(random.randint(0, 1)) for _ in range(length))\n",
        "def int_to_binary_string(n: int, length: int):\n",
        "    binary_str = bin(n)[2:]  # convert to binary string, remove '0b' prefix\n",
        "    padded_str = binary_str.rjust(length, '0')  # pad with zeros to length\n",
        "    return padded_str"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NN Based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['❤', '😍', '📷', '🇺🇸', '☀', '💜', '😉', '💯', '😁', '🎄', '📸', '😜', '😂', '☹️', '😭', '😔', '😡', '💢', '😤', '😳', '🙃', '😩', '😠', '💕', '🙈', '🙄', '🔥', '😊', '😎', '✨', '💙', '😘']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmentation_map = {'❤': ['💓', '💖', '💗', '💘', '💞', '💟'],\n",
        " '😍': ['😻', '🥰','🤩'],\n",
        " '📷': ['🎥', '📹', '🎞️', '📽️'],\n",
        " '☀': ['🌞', '🌅', '🌄', '🌤️', '🌻', '🌼'],\n",
        " '💜': ['❤️', '🤎', '🖤', '🤍'],\n",
        " '😉': ['😏', '😋', '😼', '😌', '😬'],\n",
        " '💯': ['👌'],\n",
        " '😁': ['😀', '😃', '😆', '😄', '😅', '😸'],\n",
        " '🎄': ['🎅', '🤶', '🎁', '🌟', '🌲'],\n",
        " '📸': [],\n",
        " '😜': ['😝', '😛'],\n",
        " '😂': ['🤣', '😹'],\n",
        " '☹️': ['🙁', '😞', '😖'],\n",
        " '😭': ['😢', '😥', '😪', '😓'],\n",
        " '😔': ['😟', '😕'],\n",
        " '😡': ['😣', '👿'],\n",
        " '💢': ['💥', '💨', '💣', '💫'],\n",
        " '😤': ['😒'],\n",
        " '😳': ['😮', '😯', '😲', '🙀', '😱'],\n",
        " '🙃': [],\n",
        " '😩': ['😫'],\n",
        " '😠': ['😾'],\n",
        " '💕': ['💔'],\n",
        " '🙈': ['🙉', '🙊', '🐵', '🐒', '🐾'],\n",
        " '🙄': ['😑', '🤨','😐'],\n",
        " '🔥': ['🌋', '🚒'],\n",
        " '😊': ['🙂'],\n",
        " '😎': ['🕶️', '🍻'],\n",
        " '✨': ['🔮', '🎉'],\n",
        " '💙': ['💚', '💛', '🧡'],\n",
        " '😘': ['😗', '😚', '😙']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_labels = list(augmentation_map.keys()) + [e for l in augmentation_map.values() for e in l]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(augmented_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_texts(string:str)->Generator[str, Any, None]:\n",
        "  spans = [x.span() for x in re.finditer(r'(\\s)+', string)]\n",
        "  for span in spans:\n",
        "    yield string[0:span[0]]\n",
        "  if spans[-1][1] != len(string):\n",
        "    yield string\n",
        "def gaussian_order(lst):\n",
        "    length = len(lst)\n",
        "    max_odd_ind = length - 1 if length % 2 == 0 else length - 2\n",
        "    max_even_ind = length - 1 if length % 2 != 0 else length - 2\n",
        "    dist = itertools.chain(range(max_odd_ind, 0, -2), range(0, max_even_ind + 1, 2))\n",
        "    return [lst[i] for i in dist]\n",
        "models_to_choose = [\n",
        "    \"amazon-sagemaker-community/xlm-roberta-en-ru-emoji-v2\",\n",
        "    \"AlekseyDorkin/xlm-roberta-en-ru-emoji\"\n",
        "]\n",
        "BASE_MODEL = models_to_choose[0]\n",
        "def load_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL)\n",
        "    return model, tokenizer\n",
        "MODEL, TOKENIZER = load_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple\n",
        "from math import log2\n",
        "\n",
        "class Emojier:\n",
        "  BASE_MODEL = \"amazon-sagemaker-community/xlm-roberta-en-ru-emoji-v2\"\n",
        "  model: Any = MODEL\n",
        "  tokenizer: Any = TOKENIZER\n",
        "  multiplicity = 3\n",
        "  TopFPercent = 0.1\n",
        "  verbose = False\n",
        "  \n",
        "  def __init__(self,text:str,span_size=5):\n",
        "    self.text = text\n",
        "    self.span_size = span_size\n",
        "    self._slots: Optional[List[List[Tuple[int,str]]]] = None\n",
        "    self._spaces: Optional[List[int]] = None\n",
        "    self._bits: Optional[List[int]] = None\n",
        "    \n",
        "  def getSlots(self) -> List[List[Tuple[int,str]]]:\n",
        "    if not self._slots is None:\n",
        "      return self._slots\n",
        "    self._slots = []\n",
        "    pre_slots = []\n",
        "    text = self.text\n",
        "    Emojier.info(f\"getSlots({text})\")\n",
        "    mask = MaskGen(text)\n",
        "    ss = StringSpans(text)\n",
        "    ticks = [(text[:v],(u,v)) for u,v in mask.NVA_words if (u,v) in ss.words]\n",
        "    for pre_text, (u,v) in ticks:\n",
        "      breakPoint = len(pre_text)\n",
        "      pre_text = text[:breakPoint]\n",
        "      Emojier.log('Slots>'+'-'*20 + 'tick' + '-'*20 + pre_text)\n",
        "      emoji_options = gaussian_order(Emojier._predict(text[:breakPoint]))\n",
        "      if len(emoji_options) < 2:\n",
        "        Emojier.log('Slots>'+f'word={text[u:v]},range={(0,breakPoint)},not enough options={emoji_options}')\n",
        "        continue\n",
        "      \n",
        "      pre_slots.append((breakPoint,emoji_options))\n",
        "      \n",
        "      Emojier.log('Slots>'+f\"word={text[u:v]},range={(0,breakPoint)},{len(emoji_options)}=len({emoji_options})\")\n",
        "      \n",
        "    Emojier.info(f\"detected {len(pre_slots)} slots in: {text}\")\n",
        "    self._slots = []\n",
        "    for idx, slot in enumerate(pre_slots):\n",
        "      breakPoint, emoticons = slot\n",
        "      if len(self._slots) == 0 or idx % self.span_size == 0:\n",
        "        self._slots.append([])\n",
        "      for emo in emoticons:\n",
        "        self._slots[-1].append((breakPoint,emo))\n",
        "    return self._slots\n",
        "  \n",
        "  def getSlot(self,space:int,offset:int) -> Tuple[int,str]:\n",
        "    return self.getSlots()[space][offset]\n",
        "  \n",
        "  def getSpaces(self) -> List[int]:\n",
        "    if self._spaces is None:\n",
        "      self._spaces = [len(slot) for slot in self.getSlots()]\n",
        "    return self._spaces\n",
        "  def getSpace(self,i:int):\n",
        "    return self.getSpaces()[i]\n",
        "  def getBits(self) -> List[int]:\n",
        "    if self._bits is None:\n",
        "      self._bits = [int(log2(space)) for space in self.getSpaces()]\n",
        "    return self._bits\n",
        "  def getBit(self,i: int) -> int:\n",
        "    return self.getBits()[i]\n",
        "  \n",
        "  def encode_encoder(self,bytes_str:str) -> Tuple[List[int],str]:\n",
        "    \"\"\"Encodes a bytes string using the given spaces and bits list.\n",
        "\n",
        "    Args:\n",
        "      bytes_str: The bytes string to encode.\n",
        "      spaces: A list of integers representing the number of possible values for each\n",
        "        bit in the encoded string.\n",
        "      bits_list: A list of integers representing the number of bits in each byte\n",
        "        of the encoded string.\n",
        "\n",
        "    Returns:\n",
        "      A tuple of (list of integers, string) representing the encoded bits and the\n",
        "        remaining unencoded bits.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If `bytes_str` is not a valid bytes string.\n",
        "    \"\"\"\n",
        "\n",
        "    if not all(c in ('0', '1') for c in bytes_str):\n",
        "      raise ValueError(\"bytes_str isn't a bytes string : '{}'\".format(bytes_str))\n",
        "\n",
        "    bit_values = []\n",
        "    remaining_bits = bytes_str\n",
        "    for i in range(len(self.getBits())):\n",
        "      bits = self.getBit(i)\n",
        "      if len(remaining_bits) >= bits + 1 and int(remaining_bits[:bits + 1], 2) < self.getSpace(i) and \\\n",
        "          int(remaining_bits[:bits + 1], 2) >= 2**bits:\n",
        "        bit_value = int(remaining_bits[:bits + 1], 2)\n",
        "        bit_values.append(bit_value)\n",
        "        remaining_bits = remaining_bits[bits + 1:]\n",
        "      elif len(remaining_bits) >= bits and bits > 0:\n",
        "        bit_value = int(remaining_bits[:bits], 2)\n",
        "        bit_values.append(bit_value)\n",
        "        remaining_bits = remaining_bits[bits:]\n",
        "      else:\n",
        "        bit_values.append(0)\n",
        "\n",
        "    return bit_values, remaining_bits\n",
        "\n",
        "  def decode_decoder(self,values: List[int]) -> str:\n",
        "    \"\"\"Decodes a list of integers using the given spaces and bits list.\n",
        "\n",
        "    Args:\n",
        "      values: The list of integers to decode.\n",
        "      spaces: A list of integers representing the number of possible values for each\n",
        "        bit in the encoded string.\n",
        "      bits_list: A list of integers representing the number of bits in each byte\n",
        "        of the encoded string.\n",
        "\n",
        "    Returns:\n",
        "      A string representing the decoded bytes.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If `values` is not a valid list of integers.\n",
        "    \"\"\"\n",
        "\n",
        "    if not all(isinstance(v, int) for v in values):\n",
        "      raise ValueError(\"values isn't a valid list of integers : '{}'\".format(values))\n",
        "\n",
        "    res = []\n",
        "    for i in range(len(self.getBits())):\n",
        "      space = self.getSpace(i)\n",
        "      value_to_convert = values[i]\n",
        "      if space == 0:\n",
        "        continue\n",
        "      bits = self.getBit(i)\n",
        "      v = bin(value_to_convert).replace(\"0b\", \"\")\n",
        "      v = \"0\" * max(bits - len(v), 0) + v\n",
        "      res.append(v)\n",
        "\n",
        "    return \"\".join(res)\n",
        "\n",
        "  @staticmethod\n",
        "  def predict(text: str):\n",
        "    inputs = Emojier.tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = Emojier.model(**inputs)\n",
        "    logits = outputs.logits.detach().numpy()[0]\n",
        "    predicted_class = logits.argmax()\n",
        "    return predicted_class\n",
        "    \n",
        "  @staticmethod\n",
        "  def preprocess(text:str):\n",
        "      new_text = []\n",
        "      for t in text.split(\" \"):\n",
        "          t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "          t = 'http' if t.startswith('http') else t\n",
        "          new_text.append(t)\n",
        "      return \" \".join(new_text)\n",
        "  @staticmethod\n",
        "  def _augment(emoticons:List[str]) -> List[str]:\n",
        "    augmented = []\n",
        "    for e in emoticons:\n",
        "      augmented.append(e)\n",
        "      for x in augmentation_map[e]:\n",
        "        augmented.append(x)\n",
        "    Emojier.log(f\"_augment({emoticons}) = {augmented}\")\n",
        "    return augmented\n",
        "  @staticmethod\n",
        "  def _predict(text:str) -> List[str]:\n",
        "    # Preprocess text (username and link placeholders)\n",
        "    preprocessed = Emojier.preprocess(text)\n",
        "    inputs = Emojier.tokenizer(preprocessed, return_tensors=\"pt\")\n",
        "    preds = Emojier.model(**inputs).logits\n",
        "    scores = torch.nn.functional.softmax(preds, dim=-1).detach().numpy()\n",
        "    sorted_scores = [float(value) for value in np.sort(scores.squeeze())[::-1]]\n",
        "    ranking = np.argsort(scores)\n",
        "    ranking = ranking.squeeze()[::-1]\n",
        "    emojis = [Emojier.model.config.id2label[i] for i in ranking]\n",
        "    emoticons = [emo for emo, score in zip(emojis, sorted_scores) if emo != '🇺🇸' and score > Emojier.TopFPercent]\n",
        "    return Emojier.addMultiplicities(\n",
        "        Emojier._augment(\n",
        "          emoticons\n",
        "        )\n",
        "      )\n",
        "  @staticmethod\n",
        "  def addMultiplicities(emoticons: List[str]):\n",
        "    new_emoticons = []\n",
        "    for emo in emoticons:\n",
        "      for i in range(1,Emojier.multiplicity+1):\n",
        "        new_emoticons.append(emo * i)\n",
        "    return new_emoticons\n",
        "  \n",
        "  def _encode(self,values:List[int]):\n",
        "    spaces = self.getSpaces();\n",
        "    if (len(values) > len(spaces)):\n",
        "      raise ValueError(\"Can't encode\")\n",
        "\n",
        "    for i,value in enumerate(values):\n",
        "      if value >= spaces[i] and spaces[i] != 0:\n",
        "          raise ValueError(\"Won't fit\");\n",
        "        \n",
        "\n",
        "    result = self.text;\n",
        "    for i in range(len(values)-1,-1,-1):\n",
        "      if values[i] != 0:\n",
        "        breakPoint, emoji = self.getSlot(i, values[i])\n",
        "        result = f'{result[0:breakPoint]} {emoji}{result[breakPoint:]}'\n",
        "        \n",
        "    return result\n",
        "    \n",
        "  def encode(self,bytes_str:str):\n",
        "    values, rem = self.encode_encoder(bytes_str)\n",
        "    Emojier.info(f\"encode({self.text}, {bytes_str}),values={values},rem={rem}\")\n",
        "    return self._encode(values), rem\n",
        "  \n",
        "  @staticmethod\n",
        "  def int_to_binary_string(n: int, length: int) -> str:\n",
        "    binary_str = bin(n)[2:]  # convert to binary string, remove '0b' prefix\n",
        "    padded_str = binary_str.rjust(length, '0')  # pad with zeros to length\n",
        "    return padded_str\n",
        "  @staticmethod\n",
        "  def cntPrefix(string:str, prefix:str):\n",
        "    for i in range(4,0,-1):\n",
        "    #   Emojier.log(f\"string={string[:len(prefix*i)]},prefix*i={prefix*i},string.startswith(prefix * i)={string.startswith(prefix * i)}\",end='|')\n",
        "      if string.startswith(prefix * i):\n",
        "        # Emojier.log('')\n",
        "        return i\n",
        "    # Emojier.log('')\n",
        "    return 0\n",
        "  @staticmethod\n",
        "  def log(string:str):\n",
        "    if Emojier.verbose:\n",
        "      print(string)\n",
        "    logfile = './Emojier.log'\n",
        "    with open(logfile,'a', encoding='utf-8') as f:\n",
        "      f.write(str(string)+'\\n') \n",
        "  @staticmethod\n",
        "  def info(string:str):\n",
        "    if Emojier.verbose:\n",
        "      print(string)\n",
        "    infoFile = './Emojier.info'\n",
        "    with open(infoFile,'a', encoding='utf-8') as f:\n",
        "      f.write(string+'\\n') \n",
        "  @staticmethod\n",
        "  def strip(text:str):\n",
        "    for label in augmented_labels:\n",
        "      text = text.replace(' '+label,'')\n",
        "    for label in augmented_labels:\n",
        "      text = text.replace(label,'')\n",
        "    return text\n",
        "  def first_unequal(self,a:str,b:str) -> int:\n",
        "    for i, (x,y) in enumerate(zip(a,b)):\n",
        "      if x != y:\n",
        "        return i\n",
        "    if len(a) == len(b):\n",
        "      return inf\n",
        "    else:\n",
        "      return min(len(a),len(b)) \n",
        "  def _decode(self, encoded: str):\n",
        "    slots = self.getSlots()\n",
        "    values = [0 for _ in slots]\n",
        "    old_first_unequal = self.first_unequal(encoded,self.text)\n",
        "    for i,space_slots in enumerate(slots):\n",
        "      maxValue = 0\n",
        "      for j, (_,emoji) in enumerate(space_slots):\n",
        "        values[i] = j\n",
        "        tmp = self._encode(values)\n",
        "        diff = self.first_unequal(encoded,tmp)\n",
        "        if diff > old_first_unequal:\n",
        "          old_first_unequal = diff\n",
        "          maxValue = j\n",
        "      values[i] = maxValue\n",
        "    Emojier.info(f'decode values={values}')\n",
        "    return self.decode_decoder(values)\n",
        "        \n",
        "  @staticmethod\n",
        "  def decode(encoded_text:str, span_size=5):\n",
        "    text = encoded_text\n",
        "    text = Emojier.strip(text)\n",
        "    clear_text = text\n",
        "    emo = Emojier(text,span_size)\n",
        "    return clear_text , emo._decode(encoded_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Boby = '''Hey Bob!\n",
        "\n",
        "I just read this post on ExperiencedDevs about backend generalist software engineers and their roles in tech companies. It really resonated with me and I wanted to get your take on it. Have you ever been in a similar role, and what did you think of it? Do you think it's common outside of tech companies? What advice would you give to someone looking to become a backend generalist software engineer?'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sBoby = \"\"\"I just read this post on ExperiencedDevs about backend generalist software engineers and their roles in tech companies.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_stream():\n",
        "  gened = set()\n",
        "  byte_string_length = 48\n",
        "  for i in range(2**byte_string_length):\n",
        "    x = random.randint(0,2**byte_string_length-1)\n",
        "    while x in gened:\n",
        "      x = random.randint(0,2**byte_string_length-1)\n",
        "    gened.add(x)\n",
        "    yield Emojier.int_to_binary_string(x,byte_string_length)\n",
        "    # yield x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def runTests(text=' Hello. Yes, I have always liked cars. I have a mustang convertible ',\n",
        "  data='10110011010000101110100101110000010110011000010101011011110110110100'):\n",
        "  Emojier.verbose = True\n",
        "  # for i, stream in enumerate(test_stream()):\n",
        "  for i, stream in enumerate([data]):\n",
        "    print(f'test {i} stream {stream}')\n",
        "    emo = Emojier(text)\n",
        "    enc, rem = emo.encode(stream)\n",
        "    print(\"#\"*60)\n",
        "    print(enc)\n",
        "    print(\"#\"*60)\n",
        "    org, data = emo.decode(enc)\n",
        "    print(f'ratio={len(data)}/{len(text)}={len(data)/len(text)}')\n",
        "    assert text == org\n",
        "    assert data+rem == stream\n",
        "    if i ==3:\n",
        "      break\n",
        "runTests()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Emojier Benchmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from SampleData import ConversationsRepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def runBenchmark():\n",
        "  Emojier.verbose = False\n",
        "  Emojier.TopFPercent = 0.1\n",
        "  chat_id = 4735\n",
        "  print(f\"chat_id\\tc size\\tbits\\tratio\")\n",
        "  for i in range(100):\n",
        "    for text in ConversationsRepo.get(chat_id):\n",
        "      data = random_bit_stream(len(text))\n",
        "      # data = '1' * len(text)\n",
        "      # text = 'hi, how are you?'\n",
        "      log.append((text,data))\n",
        "      emo = Emojier(text)\n",
        "      encoded_text,rem = emo.encode(data)\n",
        "      # print('rem=',rem)\n",
        "      _, deData = emo.decode(encoded_text)\n",
        "      deData += rem\n",
        "      # print(f'text=\"{text}\"\\n->\\nencoded_text=\"{encoded_text}\" \\ndata=\"{data}\"\\ndeData=\"{deData}\"\\ndata==deData=\"{data==deData}\"')\n",
        "      # print(f'ratio={len(data)-len(rem)} / {len(text)}={(len(data)-len(rem)) / len(text)}')\n",
        "      assert data==deData\n",
        "      # print('\\n')\n",
        "      \n",
        "      \n",
        "      bits = len(text)-len(rem)\n",
        "      coverSize = len(text)\n",
        "      line = f\"{chat_id}\\t{coverSize}\\t{bits}\\t{(bits*100)//coverSize}\"\n",
        "      print(line)\n",
        "      with open('benchmark.tsv','a') as f:\n",
        "        f.write(line+'\\n')\n",
        "    chat_id = random.randint(1,ConversationsRepo.ConversationsCount)\n",
        "\n",
        "\n",
        "runBenchmark()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
